{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "path_data ='//netapp/Petrel/PetrelProjects/UTM33/Employee/PSpro/DATA/Mads/DATA/'\n",
    "path_las = '//netapp/Petrel/PetrelProjects/UTM33/Employee/PSpro/DATA/Mads/DATA/well logs/'\n",
    "path_wvlt = '//netapp/Petrel/PetrelProjects/UTM33/Employee/PSpro/DATA/Mads/DATA/wavelets/'\n",
    "fig_path = 'M:/LOCRETA_WORKPACKAGE_D/Valdemar_sprint_well_data_Mads_L/MLO documents/Figures/'\n",
    "path_hrs = '//netapp/Petrel/PetrelProjects/UTM33/Employee/PSpro/DATA/Mads/DATA/HRS project/Locreta_proj_Mads_localtest.prj/seismic.dir/'\n",
    "\n",
    "plt.style.use('default')\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Arial\"\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['legend.fontsize'] = 'small'\n",
    "matplotlib.rcParams['axes.labelsize'] = 'medium'\n",
    "plt.rc('xtick',labelsize=14)\n",
    "plt.rc('ytick',labelsize=14)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-grill",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c16f590-8cdc-4128-b5e9-e8e1d11df74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = '//netapp/Petrel/PetrelProjects/UTM33/Employee/PSpro/DATA/Mads/DATA/well logs/locreta_ml/'\n",
    "df= pd.read_csv(path_project+'wells_merged_new.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['GRN',\n",
    " 'Vp',\n",
    " 'CNC',\n",
    " 'ILM_log10']\n",
    "\n",
    "target = ['Vs']\n",
    "\n",
    "train_wells = ['JUDE-1','VALDEMAR-2H', 'BOJE-2C','SIAH_NE-01X']\n",
    "\n",
    "X_train = df.loc[df['UWI'].isin(train_wells), features].values\n",
    "y_train = df.loc[df['UWI'].isin(train_wells), target].values\n",
    "\n",
    "# And we might need this later...\n",
    "wells_train = df.loc[df['UWI'].isin(train_wells), 'UWI'].values\n",
    "\n",
    "test_wells = ['BO-2X', 'BO-3X']\n",
    "\n",
    "X_test = df.loc[df['UWI'].isin(test_wells), features].values\n",
    "y_test = df.loc[df['UWI'].isin(test_wells), target].values\n",
    "len(features)\n",
    "\n",
    "test_logs = pd.DataFrame(y_test, columns = ['true'])\n",
    "\n",
    "#plt.figure(figsize=(10, 5))\n",
    "#ax = df.groupby('UWI').NEUT.count().plot(kind='bar', color=['C0', 'C1', 'C2', 'C3', 'C4', 'C5'])\n",
    "#plt.ylim(0,1300)\n",
    "#plt.xticks(rotation = 0, fontsize = 13)\n",
    "#plt.xlabel('Well name')\n",
    "#plt.ylabel('Counts')\n",
    "#for p in ax.patches:\n",
    "#    ax.annotate(str(p.get_height()),(p.get_x()+p.get_width()/2., \n",
    "#                                     p.get_height()),    ha='center',   va='center',   xytext=(0, 10),  textcoords='offset points') \n",
    "#plt.savefig(fig_path+'wells_counts.png',format='png', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c887c1c8-b0ce-40f8-be6c-eba7d5fca37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(x=df['DTS'],y = df['DENS'], c = df['DEPTH'], cmap  = 'viridis')\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef8a47-0633-42dd-842d-64fe58b3fa82",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setting up pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2380c4-484a-4275-945c-68ebb1c40538",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr1 = LinearRegression()\n",
    "regr2 = RandomForestRegressor(random_state=42, n_jobs=5)\n",
    "regr3 = SVR()\n",
    "regr4 = MLPRegressor(max_iter=1000, random_state=42, early_stopping=True, validation_fraction=0.2)\n",
    "\n",
    "\n",
    "\n",
    "# Building the pipelines\n",
    "pipe_LR = Pipeline([('std', StandardScaler()),\n",
    "                  ('LR', regr1)])\n",
    "\n",
    "pipe_RFR = Pipeline([('RFR', regr2)])\n",
    "\n",
    "pipe_SVR = Pipeline([('std', StandardScaler()),\n",
    "                 ('SVR', regr3)])\n",
    "\n",
    "pipe_MLP = Pipeline([('std', StandardScaler())\n",
    "                 , ('MLP', regr4)])\n",
    "\n",
    "# Setting up the parameter grids\n",
    "param_grid_LR = [{}]\n",
    "\n",
    "param_grid_RFR = [{ \n",
    " 'RFR__max_depth': [5, 8 ,10 ,15 ],\n",
    " 'RFR__min_samples_leaf': [ 8, 10, 12],\n",
    " 'RFR__min_samples_split': [2,3,4],\n",
    " 'RFR__n_estimators': [600 ,800, 1000] }]\n",
    "\n",
    "\n",
    "param_grid_SVR = [{'SVR__kernel' : ['linear','rbf'],\n",
    "                    'SVR__C': np.power(10., np.arange(-4, 4)),\n",
    "                  'SVR__gamma': [1, 0.1, 0.01, 0.001, 0.0001]}]\n",
    "\n",
    "param_grid_MLP = [{\"MLP__hidden_layer_sizes\": [(8,8), (14,14), (20, 20)],\n",
    "                 \"MLP__activation\": [\"relu\"],\n",
    "                 'MLP__learning_rate': ['constant','adaptive'],\n",
    "                 'MLP__solver' : ['lbfgs','adam'],\n",
    "                 \"MLP__alpha\": np.power(10., np.arange(-6, 0)),\n",
    "                 \"MLP__max_iter\": [4000],\n",
    "                  \"MLP__n_iter_no_change\":[10]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe53a3-01fe-4973-a5b3-5f3fb9e77dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6193fa3c-cd51-4cd0-8de9-4df75c75579a",
   "metadata": {},
   "source": [
    "# Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_tr = df.loc[df['UWI'].isin(train_wells), features]\n",
    "y_tr = df.loc[df['UWI'].isin(train_wells), target]\n",
    "X_ts = df.loc[df['UWI'].isin(test_wells), features]\n",
    "y_ts = df.loc[df['UWI'].isin(test_wells), target]\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "k=0\n",
    "\n",
    "nested_score_LR = []\n",
    "nested_score_RFR = []\n",
    "nested_score_SVR = []\n",
    "nested_score_MLP = []\n",
    "\n",
    "for train_index, test_index in logo.split(X_tr, y_tr, wells_train):\n",
    "    print('Iter #:', k)\n",
    "    X_trn, X_tst = X_tr.iloc[train_index], X_tr.iloc[test_index]\n",
    "    y_trn, y_tst = y_tr.iloc[train_index], y_tr.iloc[test_index]\n",
    "    \n",
    "    print('test well :', df.loc[X_tst.index[-1]]['UWI'])\n",
    "\n",
    "\n",
    "    wells_train_inner = train_wells.copy()\n",
    "    wells_train_inner.remove(df.loc[X_tst.index[-1]]['UWI'])\n",
    "    \n",
    "    print('training wells:', wells_train_inner)\n",
    "    \n",
    "    X_tr_ = df.loc[df['UWI'].isin(wells_train_inner), features].values\n",
    "    y_tr_ = np.squeeze(df.loc[df['UWI'].isin(wells_train_inner), target].values)\n",
    "\n",
    "\n",
    "    wells_train_inner = df.loc[df['UWI'].isin(wells_train_inner), 'UWI'].values\n",
    "    \n",
    "    #LR\n",
    "    gcv_LR = GridSearchCV(pipe_LR, param_grid_LR, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut(), n_jobs=-1)\n",
    "    results_LR = gcv_LR.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    model_LR = results_LR.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_LR = model_LR.predict(X_tst)\n",
    "    nested_score_LR.append(mean_squared_error(y_tst,model_score_LR, squared=False))\n",
    "    \n",
    "    #RFR\n",
    "    gcv_RFR = GridSearchCV(pipe_RFR, param_grid_RFR, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut(), n_jobs=-1)\n",
    "    results_RFR = gcv_RFR.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    print(results_RFR.best_estimator_)\n",
    "    model_RFR = results_RFR.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_RFR = model_RFR.predict(X_tst)\n",
    "    nested_score_RFR.append(mean_squared_error(y_tst,model_score_RFR, squared=False))\n",
    "    \n",
    "    \n",
    "    #SVR\n",
    "    gcv_SVR = GridSearchCV(pipe_SVR, param_grid_SVR, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut(), n_jobs=-1)\n",
    "    results_SVR = gcv_SVR.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    print(results_SVR.best_estimator_)\n",
    "    model_SVR = results_SVR.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_SVR = model_SVR.predict(X_tst)\n",
    "    nested_score_SVR.append(mean_squared_error(y_tst,model_score_SVR, squared=False))\n",
    "    \n",
    "    #MLP\n",
    "    gcv_MLP = GridSearchCV(pipe_MLP, param_grid_MLP, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut(), n_jobs=-1)\n",
    "    results_MLP = gcv_MLP.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    print(results_MLP.best_estimator_)\n",
    "    model_MLP = results_MLP.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_MLP = model_MLP.predict(X_tst)\n",
    "    nested_score_MLP.append(mean_squared_error(y_tst,model_score_MLP, squared=False))\n",
    "    \n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d707f-4c93-49d3-a143-cec0525c046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_cv = pd.DataFrame(data = np.array([nested_score_LR, nested_score_RFR, nested_score_SVR, nested_score_MLP]).T, columns = ['LR','RFR','SVR', 'MLP'])\n",
    "nested_cv.to_csv(path_project+'nested_cv.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552554a9-821f-4fa8-95ce-3c13c52c6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_cv= pd.read_csv(path_project+'nested_cv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7536be87-e7f5-411d-991f-59d063520a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b42502-5ab9-4a29-b259-61a5d77cce46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(np.arange(4), nested_cv['LR']  , label = 'LR   (RMSE mean score: {})'.format(np.round(np.mean(nested_cv['LR'] ),2)))\n",
    "plt.plot(np.arange(4), nested_cv['RFR'] , label = 'RFR (RMSE mean score: {})'.format( np.round(np.mean(nested_cv['RFR']),2)))\n",
    "plt.plot(np.arange(4), nested_cv['SVR'] , label = 'SVR (RMSE mean score:{})'.format(  np.round(np.mean(nested_cv['SVR']),2)))\n",
    "plt.plot(np.arange(4), nested_cv['MLP'] , label = 'MLPR (RMSE mean score:{})'.format( np.round(np.mean(nested_cv['MLP']),2)))\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Outer loop test well')\n",
    "plt.xticks([0,1,2,3],labels = ['BOJE-2C', 'JUDE-1', 'SIAH_NE-01X', 'VALDEMAR-2H'])\n",
    "plt.legend(fontsize = 13)\n",
    "\n",
    "plt.text(x = plt.xlim()[0]-.2,   y = plt.ylim()[1]+0.01, s = 'Figure 9',fontsize=24)\n",
    "#print('mean score LR :' , np.mean(nested_score_LR ) , 'Std:', np.std(nested_score_LR ))\n",
    "#print('mean score RFR:' , np.mean(nested_score_RFR) , 'Std:', np.std(nested_score_RFR))\n",
    "#print('mean score SVR:' , np.mean(nested_score_SVR) , 'Std:', np.std(nested_score_SVR))\n",
    "#print('mean score MLP:' , np.mean(nested_score_MLP) , 'Std:', np.std(nested_score_MLP))\n",
    "##plt.savefig(fig_path+'nested_cv.pdf',format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5155de7e-6115-4c88-92ec-d6a87038bb7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predictions on BO-2X and BO-3X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb01c3-8baa-4f22-81c0-d175480bf179",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_lr = Pipeline(steps=[('std', StandardScaler()), ('LR', LinearRegression())])\n",
    "\n",
    "estimator_rfr = Pipeline(steps=[('RFR',\n",
    "                 RandomForestRegressor(max_depth=20, min_samples_leaf=7,\n",
    "                                       n_estimators=800, n_jobs=5,\n",
    "                                       random_state=42))])\n",
    "\n",
    "estimator_svr = Pipeline(steps=[('std', StandardScaler()), ('SVR', SVR(C=0.01, gamma=0.1))])\n",
    "\n",
    "estimator_mlp = Pipeline(steps=[('std', StandardScaler()),\n",
    "                ('MLP',\n",
    "                 MLPRegressor(alpha=0.01, early_stopping=True,\n",
    "                              hidden_layer_sizes=(8, 8), max_iter=4000,\n",
    "                              random_state=42, solver='lbfgs',\n",
    "                              validation_fraction=0.2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7139e-70f9-4dc7-8066-2215d0e3e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION\n",
    "#logo = LeaveOneGroupOut().split(X_train, y_train, groups=wells_train)\n",
    "#estimator_lr = GridSearchCV(pipe_LR, param_grid_LR, scoring='neg_root_mean_squared_error', cv=logo, verbose = 1, n_jobs=-1)  \n",
    "estimator_lr.fit(X_train, np.squeeze(y_train))\n",
    "test_logs['lr'] = estimator_lr.predict(X_test)\n",
    "print('LR DONE')\n",
    "\n",
    "\n",
    "# SUPPORTVECTOR REGRESSION\n",
    "#logo = LeaveOneGroupOut().split(X_train, y_train, groups=wells_train)\n",
    "#estimator_svr = GridSearchCV(pipe_SVR, param_grid_SVR, scoring='neg_root_mean_squared_error', cv=logo, verbose = 1, n_jobs=-1)  \n",
    "estimator_svr.fit(X_train, np.squeeze(y_train))\n",
    "#print(estimator_svr.best_params_)\n",
    "#pipe_SVR.fit(X_train, y_train)\n",
    "\n",
    "test_logs['svr'] = estimator_svr.predict(X_test)\n",
    "print('SVR DONE')\n",
    "\n",
    "# RANDOMFOREST\n",
    "#logo = LeaveOneGroupOut().split(X_train, y_train, groups=wells_train)\n",
    "#pipe_RFR = Pipeline([('s',rfe), ('RFR', regr2)])\n",
    "#estimator_rfr = GridSearchCV(pipe_RFR, param_grid_RFR, scoring='neg_root_mean_squared_error', cv=logo, verbose = 1, n_jobs=-1)\n",
    "estimator_rfr.fit(X_train, np.squeeze(y_train))\n",
    "#pipe_RFR.set_params(**estimator_rfr.best_params_)\n",
    "#pipe_RFR.fit(X_train, y_train)\n",
    "test_logs['rfr'] = estimator_rfr.predict(X_test)\n",
    "print('RFR DONE')\n",
    "\n",
    "#logo = LeaveOneGroupOut().split(X_train, y_train, groups=wells_train)\n",
    "#pipe_RFR = Pipeline([('s',rfe), ('RFR', regr2)])\n",
    "#estimator_mlp = GridSearchCV(pipe_MLP, param_grid_MLP, scoring='neg_root_mean_squared_error', cv=logo, verbose = 1, n_jobs=-1)\n",
    "estimator_mlp.fit(X_train, np.squeeze(y_train))\n",
    "#pipe_MLP.set_params(**estimator_mlp.best_params_)\n",
    "#pipe_MLP.fit(X_train, y_train)\n",
    "test_logs['mlp'] = estimator_mlp.predict(X_test)\n",
    "print('MLP DONE')\n",
    "\n",
    "\n",
    "test_logs.to_csv(path_project+'wells_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b7587-26f1-4dd1-bd9f-9eacd5d0f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros([4,4])\n",
    "\n",
    "scores[0,0] = mean_squared_error(y_train , estimator_lr.predict(X_train), squared=False)\n",
    "scores[1,0] = mean_squared_error(y_train ,estimator_svr.predict(X_train), squared=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6abe7-135c-40a9-92ca-c5e25451a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros([5,5])\n",
    "\n",
    "scores[0,0] =np.round( mean_squared_error(y_train , estimator_lr.predict(X_train), squared=False),2 ) \n",
    "scores[1,0] =np.round(mean_squared_error(y_train ,estimator_rfr.predict(X_train), squared=False),2 ) \n",
    "scores[2,0] =np.round( mean_squared_error(y_train ,estimator_svr.predict(X_train), squared=False),2 ) \n",
    "scores[3,0] =np.round( mean_squared_error(y_train ,estimator_mlp.predict(X_train), squared=False),2 ) \n",
    "\n",
    "\n",
    "#scores[0,1] = mean_squared_error(test_logs['true'],test_logs['lr'],  squared=False)\n",
    "#scores[1,1] = mean_squared_error(test_logs['true'],test_logs['svr'], squared=False)\n",
    "#scores[2,1] = mean_squared_error(test_logs['true'],test_logs['rfr'], squared=False)\n",
    "#scores[3,1] = mean_squared_error(test_logs['true'],test_logs['mlp'], squared=False)\n",
    "\n",
    "\n",
    "bo2x_len = df.loc[df['UWI'] == 'BO-2X'].shape[0]\n",
    "bo3x_len = df.loc[df['UWI'] == 'BO-3X'].shape[0]\n",
    "\n",
    "scores[0,2] = np.round(mean_squared_error(test_logs['true'][:bo2x_len],test_logs['lr'][:bo2x_len],  squared=False),2)\n",
    "scores[1,2] = np.round(mean_squared_error(test_logs['true'][:bo2x_len],test_logs['rfr'][:bo2x_len], squared=False),2)\n",
    "scores[2,2] = np.round(mean_squared_error(test_logs['true'][:bo2x_len],test_logs['svr'][:bo2x_len], squared=False),2)\n",
    "scores[3,2] = np.round(mean_squared_error(test_logs['true'][:bo2x_len],test_logs['mlp'][:bo2x_len], squared=False),2)\n",
    "\n",
    "scores[0,3] = np.round(mean_squared_error(test_logs['true'][bo2x_len:],test_logs['lr'][bo2x_len:],  squared=False),2)\n",
    "scores[1,3] = np.round(mean_squared_error(test_logs['true'][bo2x_len:],test_logs['rfr'][bo2x_len:], squared=False),2)\n",
    "scores[2,3] = np.round(mean_squared_error(test_logs['true'][bo2x_len:],test_logs['svr'][bo2x_len:], squared=False),2)\n",
    "scores[3,3] = np.round(mean_squared_error(test_logs['true'][bo2x_len:],test_logs['mlp'][bo2x_len:], squared=False),2)\n",
    "\n",
    "print('LR:',mean_squared_error( test_logs['true'],test_logs['lr'], squared=False))\n",
    "print('SVR:',mean_squared_error(test_logs['true'],test_logs['rfr'], squared=False))\n",
    "print('RFR:',mean_squared_error(test_logs['true'],test_logs['svr'], squared=False))\n",
    "print('MLP:',mean_squared_error(test_logs['true'],test_logs['mlp'], squared=False))\n",
    "\n",
    "\n",
    "scores[0,1] = np.round((scores[0,2] + scores[0,3]) / 2 , 2)\n",
    "scores[1,1] = np.round((scores[1,2] + scores[1,3]) / 2 , 2)\n",
    "scores[2,1] = np.round((scores[2,2] + scores[2,3]) / 2 , 2)\n",
    "scores[3,1] = np.round((scores[3,2] + scores[3,3]) / 2 , 2)\n",
    "\n",
    "scores[0,4] = np.round(mean_squared_error(test_logs['true'][tux_start:bo2x_len],test_logs['lr'][tux_start:bo2x_len],  squared=False),2)\n",
    "scores[1,4] = np.round(mean_squared_error(test_logs['true'][tux_start:bo2x_len],test_logs['rfr'][tux_start:bo2x_len], squared=False),2)\n",
    "scores[2,4] = np.round(mean_squared_error(test_logs['true'][tux_start:bo2x_len],test_logs['svr'][tux_start:bo2x_len], squared=False),2)\n",
    "scores[3,4] = np.round(mean_squared_error(test_logs['true'][tux_start:bo2x_len],test_logs['mlp'][tux_start:bo2x_len], squared=False),2)\n",
    "scores[4,4] = 0.04 #mean_squared_error(bo2x['DTS'][tux_idx:],bo2x['Vs_IF'][tux_idx:], squared=False)  \n",
    "\n",
    "scores = pd.DataFrame(data = scores, columns = ['Mean RMSE train','Mean RMSE test','BO-2X', 'BO-3X','BO-2X Tuxen'], index=['LR','RFR','SVR','MLPR','RPM'])\n",
    "scores.to_excel(fig_path + 'scores.xlsx')#nested_cv.to_csv(path_project+'nested_cv.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36577bbe-c236-4069-923a-b694dafc4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3205246-a9f0-473b-8d44-eef1ff5bc754",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.09 + 0.05) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51198503-8da6-4d71-8e31-4c3bd00cb50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tux_start = df.loc[(df['UWI'] == 'BO-2X') & (df['Formation'] == 'U.Tuxen-1') ].index[0]\n",
    "tux_end = bo2x_len\n",
    "#loc[(bo2x['Formation'] == 'U.Tuxen-1')].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52638cd7-5245-4567-9a84-77dec0d07e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c9896-e042-44ff-a6bd-f0cf6c751bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['UWI'] == 'BO-2X') & (df['Formation'] == 'L.Tuxen-1') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cabe197-a99f-4436-982d-88d34e621eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['UWI'] == 'BO-3X'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba4a8b3-b05c-4ac7-8e6b-f590414abb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(test_logs['true'], lw=3,color='k')\n",
    "plt.plot(test_logs['lr'])\n",
    "plt.plot(test_logs['svr'])\n",
    "plt.plot(test_logs['rfr'])\n",
    "plt.plot(test_logs['mlp'])\n",
    "\n",
    "\n",
    "print('LR:',mean_squared_error(test_logs['true'],test_logs['lr'], squared=False))\n",
    "print('SVR:',mean_squared_error(test_logs['true'],test_logs['svr'], squared=False))\n",
    "print('RFR:',mean_squared_error(test_logs['true'],test_logs['rfr'], squared=False))\n",
    "print('MLP:',mean_squared_error(test_logs['true'],test_logs['mlp'], squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d5ff2-f29f-4b6f-a7a2-2c1e8414963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_rfr.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eedbf8-807a-4485-b36d-430099d29a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_svr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c78f73-b3f0-45fa-8150-05a9672ed3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_mlp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcfdaa6-3d60-4a4e-99d9-a520bf38bee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4f57d-2e88-4d78-bed9-c766b36f24ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf2b63-3dd2-4dc9-a5ac-29096b15b559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90273ea2-672f-4cb5-ae19-1a123b1f9db4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predictions on BO-2X and BO-3X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0faa2c-7431-4632-a233-60f086996746",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a298e-7512-4434-aa6a-9ffba2c75ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras import sequential\n",
    "\n",
    "#class CustomCallback(keras.callbacks.Callback):\n",
    "#\n",
    "#    def on_epoch_end(self, epoch, logs=None):\n",
    "#        y_test_pred = self.model.predict(X_test)\n",
    "#        mse = mean_squared_error(y_test, y_test_pred)\n",
    "#        print(f\"Epoch {epoch}: {mse:.2f}\")\n",
    "        \n",
    "        \n",
    "def create_model(kernel_initializer='normal', activation='relu'):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(100,input_dim=len(features),activation=activation,kernel_initializer=kernel_initializer\n",
    "                           , kernel_regularizer=regularizers.l2(0.00001)))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(100,activation=activation, kernel_regularizer=regularizers.l2(0.00001)))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(50,activation='relu', kernel_regularizer=regularizers.l2(0.00001)))\n",
    "    model.add(layers.Dense(1 ,activation=activation))\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "\n",
    "    return model\n",
    "\n",
    "# wrap the model using the function you created\n",
    "clf = KerasRegressor(model=create_model,verbose=0, epochs=200, batch_size=1, fit__validation_data = (X_test,y_test)\n",
    "                    , validation_batch_size = 1)\n",
    "\n",
    "# just create the pipeline\n",
    "pipeline_MLP = Pipeline([('std', StandardScaler()),\n",
    "    ('clf',clf)\n",
    "])\n",
    "\n",
    "pipeline_MLP.fit(X_train, y_train)\n",
    "plt.figure()\n",
    "plt.plot(pipeline_MLP.steps[1][1].history_['loss'], label = 'test')\n",
    "plt.plot(pipeline_MLP.steps[1][1].history_['val_loss'], label = 'val')\n",
    "plt.legend()\n",
    "test_logs['mlp'] = pipeline_MLP.predict(X_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_logs['true'] , label='true')\n",
    "plt.plot(test_logs['mlp'], label='pred')\n",
    "plt.legend()\n",
    "print('MLP:',mean_squared_error(test_logs['true'],test_logs['mlp'], squared=False))\n",
    "\n",
    "#test_logs['mlp'] = pipeline_MLP.predict(X_test)\n",
    "#plt.plot(test_logs['true'])\n",
    "#\n",
    "#plt.plot(test_logs['mlp'])\n",
    "#\n",
    "#print('MLP:',mean_squared_error(test_logs['true'],test_logs['mlp'], squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c68500-f224-4f95-8cbb-b25103b29ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5344a0b2-2f3e-443a-81b7-a714ee392478",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = self.model.predict(x_val)\n",
    "        mse = mean_squared_error(y_val, y_val_pred)\n",
    "        print(f\"Epoch {epoch}: {mse:.2f}\")\n",
    "        \n",
    "        \n",
    "#from tensorflow.keras import sequential\n",
    "def create_model(kernel_initializer='normal', activation='relu'):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(5,input_dim=len(features),activation=activation,kernel_initializer=kernel_initializer, kernel_regularizer=regularizers.l2(0.005)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10,activation=activation,kernel_initializer=kernel_initializer, kernel_regularizer=regularizers.l2(0.005)))\n",
    "#    model.add(layers.Dense(3,activation='relu',kernel_initializer=kernel_initializer, kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(layers.Dense(1 ,activation=activation))\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 optimizer=tf.keras.optimizers.Adam(0.1))\n",
    "\n",
    "    return model\n",
    "\n",
    "# wrap the model using the function you created\n",
    "clf = KerasRegressor(model=create_model,verbose=1)\n",
    "\n",
    "# just create the pipeline\n",
    "param_grid_MLP = [{ 'clf__batch_size': [10, 20],\n",
    " 'clf__epochs': [10, 20]}]\n",
    "\n",
    "logo = LeaveOneGroupOut().split(X_train, y_train, groups=wells_train)\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=pipeline_MLP, param_grid=param_grid_MLP, n_jobs=-1, cv=logo, return_train_score=True, scoring='neg_root_mean_squared_error')\n",
    "grid_result = grid.fit(X_train, np.squeeze(y_train))\n",
    "\n",
    "#clf_mlp.fit(X_train, np.squeeze(y_train))\n",
    "#test_logs['mlp'] = clf_mlp.predict(X_test)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "test_scores = grid_result.cv_results_['mean_test_score']\n",
    "train_scores = grid_result.cv_results_['mean_train_score'] \n",
    "#'mean_test_score': array([-0.15079611, -0.15745158, -0.12269899, -0.12267689]),\n",
    "# 'std_test_score': array([0.05027158, 0.03339824, 0.0240863 , 0.01774399]),\n",
    "plt.plot(test_scores*-1, label='validation')\n",
    "plt.plot(train_scores*-1, label='train')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5830f-d272-4f43-96bd-59432bda8128",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_MLP.set_params(**grid_result.best_params_)\n",
    "pipeline_MLP.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7dd7a-a080-4246-9947-1184184b8f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pipeline_MLP.fit(\n",
    "    X_train,\n",
    "    y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5bc938-0ff3-4e8d-b415-2c3fe9108652",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pipeline_MLP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ab90c-0243-4f08-9fb5-83e6347ccce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.steps[1][1].history_['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf37788-580a-4704-b307-2b967830c993",
   "metadata": {},
   "source": [
    "# CrossVal for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799480e-4a45-4ea4-ab91-65a3f3e54b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasRegressorMod(KerasRegressor):\n",
    "    def fit(self, X, y, sample_weight=None, validation_data=None):\n",
    "        self.fit__validation_data = validation_data\n",
    "        super().fit(X, y, sample_weight)\n",
    "        vars(self).pop('fit__validation_data')\n",
    "        return self\n",
    "    \n",
    "clf = KerasRegressorMod(model=create_model,verbose=1)\n",
    "\n",
    "# just create the pipeline\n",
    "pipeline_MLP = Pipeline([('std', StandardScaler()),\n",
    "    ('clf',clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9957fcb-8ce9-4f00-b235-30b5d1d2706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pipeline_MLP.fit(X_train, y_train, clf__validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34074766-8128-4dea-9c0f-5cbdf0bd2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.steps[1][1].history_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2f9ab-fd54-46e4-8f88-4f0ba9172cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.steps[1][1].history_['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe56d5-4716-44c4-90fc-6ceaca11a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = df.loc[df['UWI'].isin(train_wells), features]\n",
    "y_tr = df.loc[df['UWI'].isin(train_wells), target]\n",
    "X_ts = df.loc[df['UWI'].isin(test_wells), features]\n",
    "y_ts = df.loc[df['UWI'].isin(test_wells), target]\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "k=0\n",
    "\n",
    "nested_score_LR = []\n",
    "nested_score_RFR = []\n",
    "nested_score_SVR = []\n",
    "nested_score_MLP = []\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in logo.split(X_tr, y_tr, wells_train):\n",
    "    print('Iter #:', k)\n",
    "    X_trn, X_val = X_tr.iloc[train_index], X_tr.iloc[test_index]\n",
    "    y_trn, y_val = y_tr.iloc[train_index], y_tr.iloc[test_index]\n",
    "    \n",
    "    scale = StandardScaler()\n",
    "    X_trn = scale.fit_transform(X_trn)\n",
    "\n",
    "    #This is the change\n",
    "    X_val = scale.transform(X_val)\n",
    "    \n",
    "    clf.fit(X_trn, y_trn)\n",
    "    test = clf.predict(X_val)\n",
    "    #history = pipeline_MLP.fit(X_trn, y_trn, clf__validation_data=(X_val, y_val))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(test)\n",
    "    plt.plot(np.array(y_val))\n",
    "    \n",
    "    #print('test well :', df.loc[X_val.index[-1]]['UWI'])\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5a2be-b75f-40c3-b223-0c99b2429403",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.history_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3c7a0-7a09-4f96-96b7-66043c50f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.steps[1][1].history_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6cf32c-8d8a-4b8d-9322-4100a1f43c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445fdba1-aad9-4352-99c5-4b9af5865a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.77**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainties import ufloat\n",
    "from pint import UnitRegistry \n",
    "4.77\n",
    "#RMSE of test data (#1 DTC): 4.77\n",
    "#RMSE of test data (#2 DTS): 17.28\n",
    "\n",
    "DT = ufloat(200,(17.28)) *u.microsecond / u.ft\n",
    "\n",
    "format((1 / DT).to('km/s'), '.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.3048 * (1e6/(200-17.28/2) - 1e6/(200+17.28/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.3048 * (1e6/150 - 1e6/159.676)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b04bdaa-698d-43ab-8bfb-f50984fa9a6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Nested CV (LeaveOneGroupOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "regr1 = LinearRegression()\n",
    "regr2 = RandomForestRegressor(random_state=42)\n",
    "regr3 = SVR()\n",
    "regr4 = MLPRegressor(random_state=42)\n",
    "\n",
    "\n",
    "# Building the pipelines\n",
    "pipe_LR = Pipeline([('std', StandardScaler()),\n",
    "                  ('LR', regr1)])\n",
    "\n",
    "pipe_RFR = Pipeline([('RFR', regr2)])\n",
    "\n",
    "pipe_SVR = Pipeline([('std', StandardScaler()),\n",
    "                  ('SVR', regr3)])\n",
    "\n",
    "\n",
    "pipe_MLP = Pipeline([('std', StandardScaler()), ('MLP', regr4)])\n",
    "\n",
    "\n",
    "# Setting up the parameter grids\n",
    "param_grid_LR = [{}]\n",
    "\n",
    "param_grid_RFR = [{'RFR__max_depth': list(range(1, 10)) + [None],\n",
    "                  'RFR__n_estimators': [100,200,300,400] }]\n",
    "\n",
    "param_grid_SVR = [{'SVR__C': np.power(10., np.arange(-4, 4)),\n",
    "                  'SVR__gamma': [1, 0.1, 0.01, 0.001, 0.0001]}]\n",
    "\n",
    "param_grid_MLP = [{\"MLP__hidden_layer_sizes\": [(100), (10,10), (20,20), (50,50), (100,100)],\n",
    "                  \"MLP__activation\": [\"relu\"],\n",
    "                  'MLP__learning_rate': ['adaptive'],\n",
    "                  'MLP__solver' : ['adam'],\n",
    "                  \"MLP__alpha\": np.power(10., np.arange(-6, 0)),\n",
    "                  \"MLP__max_iter\": [4000]}] #np.arange(100,8000,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_tr = df.loc[df['UWI'].isin(train_wells), features]\n",
    "y_tr = df.loc[df['UWI'].isin(train_wells), target]\n",
    "X_ts = df.loc[df['UWI'].isin(test_wells), features]\n",
    "y_ts = df.loc[df['UWI'].isin(test_wells), target]\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "k=0\n",
    "\n",
    "nested_score_LR = []\n",
    "nested_score_RFR = []\n",
    "nested_score_SVR = []\n",
    "nested_score_MLP = []\n",
    "\n",
    "for train_index, test_index in logo.split(X_tr, y_tr, wells_train):\n",
    "    print('Iter #:', k)\n",
    "    X_trn, X_tst = X_tr.iloc[train_index], X_tr.iloc[test_index]\n",
    "    y_trn, y_tst = y_tr.iloc[train_index], y_tr.iloc[test_index]\n",
    "    \n",
    "    print('test well :', df.loc[X_tst.index[-1]]['UWI'])\n",
    "\n",
    "\n",
    "    wells_train_inner = train_wells.copy()\n",
    "    wells_train_inner.remove(df.loc[X_tst.index[-1]]['UWI'])\n",
    "    \n",
    "    print('training wells:', wells_train_inner)\n",
    "    \n",
    "    X_tr_ = df.loc[df['UWI'].isin(wells_train_inner), features].values\n",
    "    y_tr_ = np.squeeze(df.loc[df['UWI'].isin(wells_train_inner), target].values)\n",
    "\n",
    "\n",
    "    wells_train_inner = df.loc[df['UWI'].isin(wells_train_inner), 'UWI'].values\n",
    "    \n",
    "    #LR\n",
    "    gcv_LR = GridSearchCV(pipe_LR, param_grid_LR, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut())\n",
    "    results_LR = gcv_LR.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    model_LR = results_LR.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_LR = model_LR.predict(X_tst)\n",
    "    nested_score_LR.append(mean_squared_error(y_tst,model_score_LR, squared=False))\n",
    "    \n",
    "    #RFR\n",
    "    gcv_RFR = GridSearchCV(pipe_RFR, param_grid_RFR, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut())\n",
    "    results_RFR = gcv_RFR.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    model_RFR = results_RFR.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_RFR = model_RFR.predict(X_tst)\n",
    "    nested_score_RFR.append(mean_squared_error(y_tst,model_score_RFR, squared=False))\n",
    "    \n",
    "    \n",
    "    #SVR\n",
    "    gcv_SVR = GridSearchCV(pipe_SVR, param_grid_SVR, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut())\n",
    "    results_SVR = gcv_SVR.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    model_SVR = results_SVR.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_SVR = model_SVR.predict(X_tst)\n",
    "    nested_score_SVR.append(mean_squared_error(y_tst,model_score_SVR, squared=False))\n",
    "    \n",
    "    #MLP\n",
    "    gcv_MLP = GridSearchCV(pipe_MLP, param_grid_MLP, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut())\n",
    "    results_MLP = gcv_MLP.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    model_MLP = results_MLP.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_MLP = model_MLP.predict(X_tst)\n",
    "    nested_score_MLP.append(mean_squared_error(y_tst,model_score_MLP, squared=False))\n",
    "    \n",
    "    k+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(4), nested_score_LR  , label = 'LR')\n",
    "plt.plot(np.arange(4), nested_score_RFR , label = 'RFR')\n",
    "plt.plot(np.arange(4), nested_score_SVR , label = 'SVR')\n",
    "plt.plot(np.arange(4), nested_score_MLP , label = 'MLP')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Validation Well')\n",
    "plt.xticks([0,1,2,3],labels = ['BOJE-2C', 'JUDE-1', 'SIAH_NE-01X', 'VALDEMAR-2H'])\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.fill_between(\n",
    "    np.arange(4),\n",
    "    nested_score_LR - np.std(nested_score_LR ),\n",
    "    nested_score_LR + np.std(nested_score_LR ),\n",
    "    alpha=0.1,\n",
    "    color=\"C0\"\n",
    ")\n",
    "\n",
    "plt.fill_between(\n",
    "    np.arange(4),\n",
    "    nested_score_RFR - np.std(nested_score_RFR ),\n",
    "    nested_score_RFR + np.std(nested_score_RFR ),\n",
    "    alpha=0.1,\n",
    "    color=\"C1\"\n",
    ")\n",
    "\n",
    "plt.fill_between(\n",
    "    np.arange(4),\n",
    "    nested_score_SVR - np.std(nested_score_SVR ),\n",
    "    nested_score_SVR + np.std(nested_score_SVR ),\n",
    "    alpha=0.1,\n",
    "    color=\"C2\"\n",
    ")\n",
    "\n",
    "plt.fill_between(\n",
    "    np.arange(4),\n",
    "    nested_score_MLP - np.std(nested_score_MLP ),\n",
    "    nested_score_MLP + np.std(nested_score_MLP ),\n",
    "    alpha=0.1,\n",
    "    color=\"C2\"\n",
    ")\n",
    "\n",
    "print('mean score LR :' , np.mean(nested_score_LR ) , 'Std:', np.std(nested_score_LR ))\n",
    "print('mean score RFR:' , np.mean(nested_score_RFR) , 'Std:', np.std(nested_score_RFR))\n",
    "print('mean score SVR:' , np.mean(nested_score_SVR) , 'Std:', np.std(nested_score_SVR))\n",
    "print('mean score MLP:' , np.mean(nested_score_MLP) , 'Std:', np.std(nested_score_MLP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_score_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean score LR :' , np.mean(nested_score_LR ) , 'Std:', np.std(nested_score_LR ))\n",
    "print('mean score RFR:' , np.mean(nested_score_RFR) , 'Std:', np.std(nested_score_RFR))\n",
    "print('mean score SVR:' , np.mean(nested_score_SVR) , 'Std:', np.std(nested_score_SVR))\n",
    "print('mean score MLP:' , np.mean(nested_score_MLP) , 'Std:', np.std(nested_score_MLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_MLP.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logo = LeaveOneGroupOut().split(X_train, y_train, groups=wells_train)\n",
    "#nested_score = cross_val_score(results.best_estimator_, X_train, y_train, scoring='neg_root_mean_squared_error', cv=logo, groups=wells_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7dd21a-714c-44ba-b2b0-0e31ebbbaeb3",
   "metadata": {},
   "source": [
    "# Nested CV with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=10)\n",
    "\n",
    "\n",
    "regr1 = LinearRegression()\n",
    "regr2 = RandomForestRegressor(random_state=42)\n",
    "regr3 = SVR()\n",
    "regr4 = MLPRegressor(random_state=42)\n",
    "\n",
    "\n",
    "# Building the pipelines\n",
    "pipe_LR = Pipeline([('s',rfe) , ('std', StandardScaler()),\n",
    "                  ('LR', regr1)])\n",
    "\n",
    "pipe_RFR = Pipeline([('s',rfe), ('RFR', regr2)])\n",
    "\n",
    "pipe_SVR = Pipeline([('s',rfe) , ('std', StandardScaler()),\n",
    "                  ('SVR', regr3)])\n",
    "\n",
    "\n",
    "pipe_MLP = Pipeline([('s',rfe), ('std', StandardScaler()), ('MLP', regr4)])\n",
    "\n",
    "\n",
    "# Setting up the parameter grids\n",
    "param_grid_LR = [{}]\n",
    "\n",
    "param_grid_RFR = [{'RFR__max_depth': list(range(1, 10)) + [None],\n",
    "                  'RFR__n_estimators': [100,200,300,400] }]\n",
    "\n",
    "param_grid_SVR = [{'SVR__C': np.power(10., np.arange(-4, 4)),\n",
    "                  'SVR__gamma': [1, 0.1, 0.01, 0.001, 0.0001]}]\n",
    "\n",
    "param_grid_MLP = [{\"MLP__hidden_layer_sizes\": [(100), (10,10), (20,20), (50,50), (100,100)],\n",
    "                  \"MLP__activation\": [\"relu\"],\n",
    "                  'MLP__learning_rate': ['adaptive'],\n",
    "                  'MLP__solver' : ['adam'],\n",
    "                  \"MLP__alpha\": np.power(10., np.arange(-6, 0)),\n",
    "                  \"MLP__max_iter\": [4000]}] #np.arange(100,8000,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_tr = df.loc[df['UWI'].isin(train_wells), features]\n",
    "y_tr = df.loc[df['UWI'].isin(train_wells), target]\n",
    "X_ts = df.loc[df['UWI'].isin(test_wells), features]\n",
    "y_ts = df.loc[df['UWI'].isin(test_wells), target]\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "k=0\n",
    "\n",
    "nested_score_LR = []\n",
    "nested_score_RFR = []\n",
    "nested_score_SVR = []\n",
    "nested_score_MLP = []\n",
    "\n",
    "for train_index, test_index in logo.split(X_tr, y_tr, wells_train):\n",
    "    print('Iter #:', k)\n",
    "    X_trn, X_tst = X_tr.iloc[train_index], X_tr.iloc[test_index]\n",
    "    y_trn, y_tst = y_tr.iloc[train_index], y_tr.iloc[test_index]\n",
    "    \n",
    "    print('test well :', df.loc[X_tst.index[-1]]['UWI'])\n",
    "\n",
    "\n",
    "    wells_train_inner = train_wells.copy()\n",
    "    wells_train_inner.remove(df.loc[X_tst.index[-1]]['UWI'])\n",
    "    \n",
    "    print('training wells:', wells_train_inner)\n",
    "    \n",
    "    X_tr_ = df.loc[df['UWI'].isin(wells_train_inner), features].values\n",
    "    y_tr_ = np.squeeze(df.loc[df['UWI'].isin(wells_train_inner), target].values)\n",
    "\n",
    "\n",
    "    wells_train_inner = df.loc[df['UWI'].isin(wells_train_inner), 'UWI'].values\n",
    "    \n",
    "    #LR\n",
    "    gcv_LR = GridSearchCV(pipe_LR, param_grid_LR, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut())\n",
    "    results_LR = gcv_LR.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    model_LR = results_LR.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_LR = model_LR.predict(X_tst)\n",
    "    nested_score_LR.append(mean_squared_error(y_tst,model_score_LR, squared=False))\n",
    "    \n",
    "    #RFR\n",
    "    gcv_RFR = GridSearchCV(pipe_RFR, param_grid_RFR, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut())\n",
    "    results_RFR = gcv_RFR.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    model_RFR = results_RFR.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_RFR = model_RFR.predict(X_tst)\n",
    "    nested_score_RFR.append(mean_squared_error(y_tst,model_score_RFR, squared=False))\n",
    "    \n",
    "    \n",
    "    #SVR\n",
    "    gcv_SVR = GridSearchCV(pipe_SVR, param_grid_SVR, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut())\n",
    "    results_SVR = gcv_SVR.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    model_SVR = results_SVR.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_SVR = model_SVR.predict(X_tst)\n",
    "    nested_score_SVR.append(mean_squared_error(y_tst,model_score_SVR, squared=False))\n",
    "    \n",
    "    #MLP\n",
    "    gcv_MLP = GridSearchCV(pipe_MLP, param_grid_MLP, scoring='neg_root_mean_squared_error', cv=LeaveOneGroupOut())\n",
    "    results_MLP = gcv_MLP.fit(X_tr_, y_tr_, groups=wells_train_inner)\n",
    "    model_MLP = results_MLP.best_estimator_.fit(X_tr_, y_tr_)\n",
    "    model_score_MLP = model_MLP.predict(X_tst)\n",
    "    nested_score_MLP.append(mean_squared_error(y_tst,model_score_MLP, squared=False))\n",
    "    \n",
    "    k+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(4), nested_score_LR  , label = 'LR')\n",
    "plt.plot(np.arange(4), nested_score_RFR , label = 'RFR')\n",
    "plt.plot(np.arange(4), nested_score_SVR , label = 'SVR')\n",
    "plt.plot(np.arange(4), nested_score_MLP , label = 'MLP')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Validation Well')\n",
    "plt.xticks([0,1,2,3],labels = ['BOJE-2C', 'JUDE-1', 'SIAH_NE-01X', 'VALDEMAR-2H'])\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.fill_between(\n",
    "    np.arange(4),\n",
    "    nested_score_LR - np.std(nested_score_LR ),\n",
    "    nested_score_LR + np.std(nested_score_LR ),\n",
    "    alpha=0.1,\n",
    "    color=\"C0\"\n",
    ")\n",
    "\n",
    "plt.fill_between(\n",
    "    np.arange(4),\n",
    "    nested_score_RFR - np.std(nested_score_RFR ),\n",
    "    nested_score_RFR + np.std(nested_score_RFR ),\n",
    "    alpha=0.1,\n",
    "    color=\"C1\"\n",
    ")\n",
    "\n",
    "plt.fill_between(\n",
    "    np.arange(4),\n",
    "    nested_score_SVR - np.std(nested_score_SVR ),\n",
    "    nested_score_SVR + np.std(nested_score_SVR ),\n",
    "    alpha=0.1,\n",
    "    color=\"C2\"\n",
    ")\n",
    "\n",
    "plt.fill_between(\n",
    "    np.arange(4),\n",
    "    nested_score_MLP - np.std(nested_score_MLP ),\n",
    "    nested_score_MLP + np.std(nested_score_MLP ),\n",
    "    alpha=0.1,\n",
    "    color=\"C2\"\n",
    ")\n",
    "\n",
    "print('mean score LR :' , np.mean(nested_score_LR ) , 'Std:', np.std(nested_score_LR ))\n",
    "print('mean score RFR:' , np.mean(nested_score_RFR) , 'Std:', np.std(nested_score_RFR))\n",
    "print('mean score SVR:' , np.mean(nested_score_SVR) , 'Std:', np.std(nested_score_SVR))\n",
    "print('mean score MLP:' , np.mean(nested_score_MLP) , 'Std:', np.std(nested_score_MLP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean score LR : 0.12636835831088702 Std: 0.03289854152198718\n",
    "mean score RFR: 0.11639220359273304 Std: 0.026268406898577686\n",
    "mean score SVR: 0.10196428215112074 Std: 0.03725603668502954\n",
    "mean score MLP: 0.10148377149739016 Std: 0.05692889168846151\n",
    "        \n",
    "        \n",
    "mean score LR : 0.11630283448532498 Std: 0.059124087596068776\n",
    "mean score RFR: 0.11248545517280101 Std: 0.023239336498082918\n",
    "mean score SVR: 0.11043857509214851 Std: 0.047871997594650495\n",
    "mean score MLP: 0.08996400743992972 Std: 0.045256619671477455"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
