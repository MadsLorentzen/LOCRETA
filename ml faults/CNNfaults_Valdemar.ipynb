{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Prediction with a pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from unet3 import *\n",
    "\n",
    "# load json and create model \n",
    "json_file = open('model/model3.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model/pretrained_model.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# training image dimensions\n",
    "n1, n2, n3 = 128, 128, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set gaussian weights in the overlap bounaries\n",
    "def getMask(os):\n",
    "    sc = np.zeros((n1,n2,n3),dtype=np.single)\n",
    "    sc = sc+1\n",
    "    sp = np.zeros((os),dtype=np.single)\n",
    "    sig = os/4\n",
    "    sig = 0.5/(sig*sig)\n",
    "    for ks in range(os):\n",
    "        ds = ks-os+1\n",
    "        sp[ks] = np.exp(-ds*ds*sig)\n",
    "    for k1 in range(os):\n",
    "        for k2 in range(n2):\n",
    "            for k3 in range(n3):\n",
    "                sc[k1][k2][k3]=sp[k1]\n",
    "                sc[n1-k1-1][k2][k3]=sp[k1]\n",
    "    for k1 in range(n1):\n",
    "        for k2 in range(os):\n",
    "            for k3 in range(n3):\n",
    "                sc[k1][k2][k3]=sp[k2]\n",
    "                sc[k1][n3-k2-1][k3]=sp[k2]\n",
    "    for k1 in range(n1):\n",
    "        for k2 in range(n2):\n",
    "            for k3 in range(os):\n",
    "                sc[k1][k2][k3]=sp[k3]\n",
    "                sc[k1][k2][n3-k3-1]=sp[k3]\n",
    "    return sc\n",
    "\n",
    "def predictWithMask(gx):\n",
    "    os = 12 #overlap width\n",
    "    c1 = np.round((m1+os)/(n1-os)+0.5)\n",
    "    c2 = np.round((m2+os)/(n2-os)+0.5)\n",
    "    c3 = np.round((m3+os)/(n3-os)+0.5)\n",
    "    c1 = int(c1)\n",
    "    c2 = int(c2)\n",
    "    c3 = int(c3)\n",
    "    p1 = (n1-os)*c1+os\n",
    "    p2 = (n2-os)*c2+os\n",
    "    p3 = (n3-os)*c3+os\n",
    "    gx = np.reshape(gx,(m1,m2,m3))\n",
    "    gp = np.zeros((p1,p2,p3),dtype=np.single)\n",
    "    gy = np.zeros((p1,p2,p3),dtype=np.single)\n",
    "    mk = np.zeros((p1,p2,p3),dtype=np.single)\n",
    "    gs = np.zeros((1,n1,n2,n3,1),dtype=np.single)\n",
    "    gp[0:m1,0:m2,0:m3]=gx\n",
    "    sc = getMask(os)\n",
    "    for k1 in range(c1):\n",
    "        for k2 in range(c2):\n",
    "            for k3 in range(c3):\n",
    "                b1 = k1*n1-k1*os\n",
    "                e1 = b1+n1\n",
    "                b2 = k2*n2-k2*os\n",
    "                e2 = b2+n2\n",
    "                b3 = k3*n3-k3*os\n",
    "                e3 = b3+n3\n",
    "                gs[0,:,:,:,0]=gp[b1:e1,b2:e2,b3:e3]\n",
    "                gs = gs-np.min(gs)\n",
    "                gs = gs/np.max(gs)\n",
    "                gs = gs*255 \n",
    "                Y = loaded_model.predict(gs,verbose=1)\n",
    "                Y = np.array(Y)\n",
    "                gy[b1:e1,b2:e2,b3:e3]= gy[b1:e1,b2:e2,b3:e3]+Y[0,:,:,:,0]*sc\n",
    "                mk[b1:e1,b2:e2,b3:e3]= mk[b1:e1,b2:e2,b3:e3]+sc\n",
    "    gy = gy/mk\n",
    "    gy = gy[0:m1,0:m2,0:m3]\n",
    "    return gx, gy\n",
    "\n",
    "def stdMin(gx):\n",
    "    gm = np.mean(gx)\n",
    "    gs = np.std(gx)\n",
    "    gx = gx-gm\n",
    "    gx = gx/gs\n",
    "    return gx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## ======================================================================\n",
    "\n",
    "## prediction test on a field seismic image extracted from\n",
    "\n",
    "## Valdemar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import segyio\n",
    "%matplotlib inline\n",
    "\n",
    "seismPath = 'C:/Users/vwt756/OneDrive - GEUS/MLO documents/pythoncode_local/LOCRETA/data/seismic/Valdemar_full_stack_scaled_1.sgy' #\"E:/ForVideoSegy/CanningCut.segy\"\n",
    "gx = segyio.tools.cube(seismPath)\n",
    "print (gx.shape)\n",
    "fault_dummy = np.zeros(gx.shape)\n",
    "#gx= gx[:, :, :256]\n",
    "gx= gx[:, :, 90:346]\n",
    "m1,m2, m3 = gx.shape[0], gx.shape[1], gx.shape[2]\n",
    "gx = stdMin(gx)\n",
    "print (gx.shape)\n",
    "gx, gy = predictWithMask(gx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.5 + (120*0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "from PIL import Image\n",
    "#gx,m1,m2,m3 = np.fromfile(\"data/prediction/f3d/gxl.dat\",dtype=np.single),512,384,128\n",
    "#gy.tofile(\"data/prediction/f3d/\"+\"fp.dat\",format=\"%4\")\n",
    "\n",
    "gx = np.reshape(gx,(m1,m2,m3))\n",
    "gy = np.reshape(gy,(m1,m2,m3))\n",
    "\n",
    "k1,k2,k3 = 150,250,110\n",
    "gx1 = np.transpose(gx[k1,:,:])\n",
    "gy1 = np.transpose(gy[k1,:,:])\n",
    "gx2 = np.transpose(gx[:,k2,:])\n",
    "gy2 = np.transpose(gy[:,k2,:])\n",
    "gx3 = np.transpose(gx[:,:,k3])\n",
    "gy3 = np.transpose(gy[:,:,k3])\n",
    "\n",
    "#xline slice\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "p1 = plt.subplot(1, 2, 1)\n",
    "p1.imshow(gx1,aspect=1.5,cmap=plt.cm.gray)\n",
    "p2 = plt.subplot(1,2,2)\n",
    "p2.imshow(gy1,aspect=1.5,interpolation=\"bilinear\",vmin=0.9,vmax=1.0,cmap=plt.cm.gray)\n",
    "\n",
    "#inline slice\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "p1 = plt.subplot(1, 2, 1)\n",
    "p1.imshow(gx2,aspect=1.5,cmap=plt.cm.gray)\n",
    "p2 = plt.subplot(1,2,2)\n",
    "p2.imshow(gy2,aspect=1.5,interpolation=\"bilinear\",vmin=0.9,vmax=1.0,cmap=plt.cm.gray)\n",
    "\n",
    "#time slice\n",
    "fig = plt.figure(figsize=(22,22))\n",
    "p1 = plt.subplot(1, 2, 1)\n",
    "p1.imshow(gx3,cmap=plt.cm.gray)\n",
    "p2 = plt.subplot(1,2,2)\n",
    "p2.imshow(gy3,interpolation=\"bilinear\",vmin=0.9,vmax=1.0,cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_dummy[:,:,90:346] = gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fault_dummy[40,:,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdemar =  seismPath\n",
    "from segysak.segy import segy_loader\n",
    "valdemar = segy_loader(valdemar ,cdp=None, iline=189, xline=193,cdpx=181, cdpy = 185,  vert_domain='TWT', data_type='AMP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dummy = stdMin(valdemar.data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dim = valdemar.data.shape\n",
    "idx = np.arange(0, dim[0])\n",
    "print(np.amin(idx), np.amax(idx))\n",
    "\n",
    "lns = np.arange(np.amin(valdemar.data.iline), np.amax(valdemar.data.iline)+1,2)\n",
    "print(np.amin(lns), np.amax(lns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segyio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "input_file = seismPath\n",
    "output_file =  \"C:/Users/vwt756/OneDrive - GEUS/MLO documents/pythoncode_local/LOCRETA/data/seismic/Valdemar_faults_review.sgy\"\n",
    "\n",
    "copyfile(input_file, output_file)\n",
    "#iline=189, xline=193,cdpx=181, cdpy = 185\n",
    "with segyio.open(output_file,  \"r+\", iline=189, xline=193) as dst:\n",
    "    for i,j in zip(lns,idx):\n",
    "        dst.iline[i] = fault_dummy[j,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "input_file = seismPath\n",
    "output_file =  \"C:/Users/vwt756/OneDrive - GEUS/MLO documents/pythoncode_local/LOCRETA/data/seismic/Valdemar_processedcube_review.sgy\"\n",
    "\n",
    "copyfile(input_file, output_file)\n",
    "#iline=189, xline=193,cdpx=181, cdpy = 185\n",
    "with segyio.open(output_file,  \"r+\", iline=189, xline=193) as dst:\n",
    "    for i,j in zip(lns,idx):\n",
    "        dst.iline[i] = processed_dummy[j,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube =  \"C:/Users/vwt756/OneDrive - GEUS/MLO documents/pythoncode_local/LOCRETA/data/seismic/Valdemar_faults_review.sgy\"\n",
    "from segysak.segy import segy_loader\n",
    "cnn = segy_loader(cube ,cdp=None, iline=189, xline=193,cdpx=181, cdpy = 185,  vert_domain='TWT', data_type='AMP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stenlille[\"CNN\"] = ((\"iline\", \"xline\", \"twt\"), fault_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "from ipywidgets import interactive\n",
    "\n",
    "def f(m):\n",
    "    plt.figure(figsize=(15,10))\n",
    "#    plt.imshow(gx[:,:,m], cmap='seismic',vmin=-5,vmax=5)\n",
    "    plt.imshow(valdemar.data.data[:,m,88:600].T, cmap='seismic',) # alpha=0.5,# vmin=.60,vmax=1)\n",
    "    plt.imshow(cnn.data.data[:,m,88:600].T, cmap='Greys',alpha=.5,vmin=.95,vmax=1) # alpha=0.5,# vmin=.60,vmax=1)\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(f, m=(0, 470))\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '500px'\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d8d1e1b1d20f1b12961c616d01893b5202fddd228ce4d41d19bb673afdbb645"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
